# -*- coding: utf-8 -*-
"""News Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VYoCiuup_EtEwaMnwQdIyxQVU_aOo4BE
"""

import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import nltk

from tensorflow import keras
from keras.preprocessing.text import text_to_word_sequence
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder

dataset = pd.read_csv('/content/drive/MyDrive/Dataset/News/data_stemming.csv')
dataset.head(1)

dataset = pd.read_excel('/content/drive/MyDrive/Dataset/News/Dataset News Indonesia.xlsx')
dataset.head()

dataset.drop(columns=['Article Title', 'Article Link','Unnamed: 0'],inplace=True)

dataset

target_category = dataset['Kategori'].unique()
print(target_category)

dataset['KategoriId'] = dataset['Kategori'].factorize()[0]
dataset.head()

category = dataset[["Kategori","KategoriId"]].drop_duplicates().sort_values('KategoriId')
category

dataset.groupby('Kategori').KategoriId.count()

dataset.groupby('Kategori').KategoriId.count().plot.bar(ylim=0)

text = dataset["Article Content"] 
text.head()

category = dataset["Kategori"]
category.head()

import re
def casefolding(Casefold):
  Casefold = Casefold.lower()
  Casefold = Casefold.strip(" ")
  Casefold = re.sub(r'[?|$|.|!2_:@\/#")(-+]','',Casefold)
  return Casefold
dataset['Article Content'] = dataset['Article Content'].apply(casefolding)
dataset.head(1)

#tokenizing

def token(ArticleContent):
    nstr =ArticleContent.split(',')
    dat=[]
    a = -1 
    for hu in nstr:
        a = a + 1
    if hu == '':
        dat.append(a)
    p = 0
    b = 0
    for q in dat:
        b = q - p
        del nstr[b]
        p = p + 1
    return nstr
dataset['Article Content'] = dataset['Article Content'].apply(token)
dataset.head(1)

#proses filtering

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

def stopword_removal(stopp):
    filtering = stopwords.words('indonesian','english')
    x = []
    data = []
    def myFunc(x):
      if x in filtering:
        return False
      else:
        return True
    fit = filter(myFunc, stopp)
    for x in fit:
        data.append(x)
    return data
dataset['Article Content'] = dataset['Article Content'].apply(stopword_removal)
dataset.head(1)

# proses steming

from sklearn.pipeline import Pipeline
!pip install Sastrawi
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

def stemming(Stemm):
  factory = StemmerFactory()
  stemmer = factory.create_stemmer()
  do = []
  for w in Stemm:
      dt = stemmer.stem(w)
      do.append(dt)
  d_clean=[]
  d_clean= "".join(do)
  print(d_clean)
  return d_clean
dataset['Article Content'] = dataset['Article Contact'].apply(stemming)

dataset.to_csv('data_stemming3.csv', index=False)
data_clean = pd.read_csv('data_stemming3.csv', encoding='latin1')
data_clean.head()

X_train, X_test, Y_train, Y_test = train_test_split(text,category, test_size = 0.3,
                                                    random_state = 60,shuffle=True, stratify=category)

print(len(X_train))
print(len(X_test))

knn = Pipeline([('tfidf', TfidfVectorizer()),
                ('knn', KNeighborsClassifier()),
               ])

knn.fit(X_train, Y_train)

test_predict = knn.predict(X_test)

train_accuracy = round(knn.score(X_train,Y_train)*100)
test_accuracy =round(accuracy_score(test_predict, Y_test)*100)

print("K-Nearest Neighbour Train Accuracy Score : {}% ".format(train_accuracy ))
print("K-Nearest Neighbour Test Accuracy Score  : {}% ".format(test_accuracy ))
print()
print(classification_report(test_predict, Y_test, target_names=target_category))

rfc = Pipeline([('tfidf', TfidfVectorizer()),
                ('rfc', RandomForestClassifier(n_estimators=100)),
               ])

rfc.fit(X_train, Y_train)

test_predict = rfc.predict(X_test)

train_accuracy = round(rfc.score(X_train,Y_train)*100)
test_accuracy =round(accuracy_score(test_predict, Y_test)*100)

print("Random Forest Train Accuracy Score : {}% ".format(train_accuracy ))
print("Random Forest Test Accuracy Score  : {}% ".format(test_accuracy ))
print()
print(classification_report(test_predict, Y_test, target_names=target_category))